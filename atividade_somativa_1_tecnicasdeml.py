# -*- coding: utf-8 -*-
"""Atividade_Somativa_1_tecnicasdeML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10OKiEjdedU7lMci0o6xR1zWk-U3iNdnz
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from google.colab import drive
import matplotlib.pyplot as plt

# 1 - Carregar o dataset
# O dataset foi disponibilizado pela universidade e contém medições físicas realizadas pela NASA.
# Cada linha representa um teste, e o objetivo é prever o scaled-sound-pressure.
# Vamos carregar o arquivo diretamente do Google Drive e inspecionar sua estrutura.

# Montar o Google Drive
drive.mount('/content/drive')

# Caminho do arquivo
path = '/content/drive/MyDrive/nasa/nasa.csv'

# Carregar o dataset
df = pd.read_csv(path, sep=';')

# Exibir as primeiras linhas
print("--- Primeiras 5 linhas do dataset ---")
display(df.head())

# Informações gerais
print("\n--- Informações do Dataset ---")
df.info()

# Estatísticas descritivas
print("\n--- Estatísticas Descritivas ---")
display(df.describe())

# 2 - Definir variáveis preditoras (X) e alvo (y)
# O alvo é a coluna scaled-sound-pressure, e todas as demais colunas serão usadas como features.

target_column = 'scaled-sound-pressure'
features = [col for col in df.columns if col != target_column]

X = df[features]
y = df[target_column]

print(f"Features (X): {features}")
print(f"Alvo (y): {target_column}")

# 3 - Dividir os dados em treino e teste
# Treino:75%
# Teste:25%
# A divisão é importante para avaliar o modelo com dados que ele nunca viu.

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)

print(f"Tamanho total: {len(df)} registros")
print(f"Treino: {len(X_train)} registros (75%)")
print(f"Teste: {len(X_test)} registros (25%)")

# 4 - Preparação dos dados
# Vamos aplicar duas técnicas principais:
# Normalização (StandardScaler) - garante que todas as features fiquem na mesma escala.
# Seleção de atributos (SelectKBest) - escolhe automaticamente as variáveis mais relevantes para prever o alvo.

# Normalização
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Converter de volta para DataFrame
X_train_scaled = pd.DataFrame(X_train_scaled, columns=features)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=features)

print("--- Normalização concluída ---")
display(X_train_scaled.head())

# Seleção de atributos
k_best = 4
selector = SelectKBest(score_func=f_regression, k=k_best)
selector.fit(X_train_scaled, y_train)

selected_features = X_train_scaled.columns[selector.get_support()]
print(f"As {k_best} melhores features selecionadas são: {list(selected_features)}")

X_train_selected = selector.transform(X_train_scaled)
X_test_selected = selector.transform(X_test_scaled)

print(f"\nDimensão original: {X_train_scaled.shape}")
print(f"Após seleção: {X_train_selected.shape}")

# 5 - Treinamento do modelo
# Usaremos o Random Forest Regressor, um algoritmo supervisionado baseado em várias árvores de decisão. Ele é robusto, lida bem com dados não lineares e fornece bons resultados mesmo sem ajuste fino.

model = RandomForestRegressor(n_estimators=100, random_state=42)
print("Treinando o modelo...")
model.fit(X_train_selected, y_train)
print("Treinamento concluído!")

print("Treinamento finalizado!")

# 6 - Predição e Avaliação do modelo
# Agora faremos predições com a base de teste e avaliaremos o desempenho com métricas adequadas a problemas de regressão:
# R² (Coeficiente de Determinação) - mede a qualidade do ajuste.
# MAE (Erro Absoluto Médio) - erro médio em valores absolutos.
# RMSE (Raiz do Erro Quadrático Médio) - dá peso maior a grandes erros.

# Fazer predições
y_pred = model.predict(X_test_selected)

# Calcular métricas
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("\n--- Métricas de Avaliação ---")
print(f"R²: {r2:.4f}")
print(f"MAE: {mae:.4f} dB")
print(f"RMSE: {rmse:.4f} dB")

# 7 - Comparação entre valores reais e previstos

results_df = pd.DataFrame({
    'Valor Real': y_test.reset_index(drop=True),
    'Valor Previsto': y_pred
})

display(results_df.head(10))

# 8 - Visualização Gráfica
# O gráfico abaixo mostra a relação entre os valores reais e os previstos. Quanto mais próximos os pontos estiverem da diagonal, melhor o modelo.

plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.xlabel("Valor Real (dB)")
plt.ylabel("Valor Previsto (dB)")
plt.title("Relação entre Valores Reais e Previstos")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')
plt.show()

# Conclusão
# - O problema tratado é de regressão supervisionada.
# - Foram aplicadas técnicas de normalização e seleção de atributos.
# - O modelo escolhido foi o Random Forest Regressor, da biblioteca scikit-learn.
# - As métricas apresentaram desempenho satisfatório para uma primeira versão.

!jupyter nbconvert --to html "/content/drive/MyDrive/Atividade_Somativa_1_tecnicasdeML.ipynb"

from google.colab import files
files.download("/content/drive/MyDrive/Atividade_Somativa_1_tecnicasdeML.html")